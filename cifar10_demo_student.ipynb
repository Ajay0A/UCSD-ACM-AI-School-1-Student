{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Demo - Image Classification\n",
    "\n",
    "Welcome to Computer Vision! In this demo, you'll learn how computers can recognize objects in images.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. **Image Classification Basics** - Teaching computers to recognize objects\n",
    "2. **Feature Engineering** - The old-school approach (manually designed features)\n",
    "3. **Data Augmentation** - Making models work in different conditions\n",
    "4. **CNNs (Convolutional Neural Networks)** - The modern deep learning approach\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Import Libraries\n",
    "\n",
    "**What are these?**\n",
    "- **PyTorch**: A deep learning framework (like TensorFlow)\n",
    "- **torchvision**: Computer vision tools for PyTorch\n",
    "- **NumPy**: For numerical operations\n",
    "- **Matplotlib**: For visualizing images\n",
    "- **scikit-learn**: Traditional machine learning tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from skimage.feature import hog\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Check what hardware we're using\n",
    "# GPU (CUDA/MPS) is faster than CPU for deep learning\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \n",
    "                      \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Understanding the Data\n",
    "\n",
    "**What is CIFAR-10?**\n",
    "\n",
    "CIFAR-10 is a famous dataset used to teach computers image recognition. It contains 60,000 tiny color images.\n",
    "\n",
    "**Key Facts:**\n",
    "- **Image size**: 32×32 pixels (very small!)\n",
    "- **10 classes**: airplane, car, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- **50,000 training images**: Used to teach the model\n",
    "- **10,000 test images**: Used to check how well the model learned\n",
    "\n",
    "**Why so small?** Small images are harder to recognize (even for humans!), but they train faster. This helps us learn the concepts quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "# ToTensor() converts images to tensors (multi-dimensional arrays that computers understand)\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"Training images: {len(train_dataset)}\")\n",
    "print(f\"Test images: {len(test_dataset)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Images\n",
    "\n",
    "Let's look at one image from each class to see what we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show one example from each class\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for idx, class_name in enumerate(classes):\n",
    "    # Find first image of this class\n",
    "    for i in range(len(train_dataset)):\n",
    "        img, label = train_dataset[i]\n",
    "        if label == idx:\n",
    "            ax = axes[idx // 5, idx % 5]\n",
    "            # Convert tensor (C, H, W) to numpy (H, W, C) for display\n",
    "            img_np = img.permute(1, 2, 0).numpy()\n",
    "            ax.imshow(img_np)\n",
    "            ax.set_title(class_name)\n",
    "            ax.axis('off')\n",
    "            break\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check image dimensions\n",
    "sample_img, _ = train_dataset[0]\n",
    "print(f\"\\nImage shape: {sample_img.shape}\")  # (channels, height, width)\n",
    "print(\"That's 3 color channels (RGB), 32 pixels tall, 32 pixels wide!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Engineering (The Old Way)\n",
    "\n",
    "**The Big Idea:** Before deep learning, humans had to manually tell computers what to look for.\n",
    "\n",
    "**How it works:**\n",
    "1. **Humans design features** - We decide what's important (edges, shapes, colors)\n",
    "2. **Extract features** - Use algorithms to measure these things in images\n",
    "3. **Train a simple classifier** - Teach it to recognize patterns in the features\n",
    "\n",
    "**Example Algorithm: HOG (Histogram of Oriented Gradients)**\n",
    "- Detects edges and their directions in the image\n",
    "- Converts an image into a list of numbers describing its edges\n",
    "\n",
    "**The Problem:**\n",
    "- Humans aren't good at knowing what features matter!\n",
    "- Performance is limited (~40-50% accuracy on CIFAR-10)\n",
    "- That's why deep learning took over!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(dataset, num_samples=5000):\n",
    "    \"\"\"\n",
    "    Extract HOG features from images\n",
    "    \n",
    "    HOG finds edges in images and describes them with numbers.\n",
    "    Think of it like describing a person: \"tall, brown hair, glasses\"\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in tqdm(range(min(num_samples, len(dataset))), desc=\"Extracting features\"):\n",
    "        img, label = dataset[i]\n",
    "        # Convert to grayscale (black & white) for HOG\n",
    "        img_gray = img.mean(dim=0).numpy()\n",
    "        \n",
    "        # Extract HOG features\n",
    "        feat = hog(img_gray, pixels_per_cell=(4, 4), cells_per_block=(2, 2), orientations=9)\n",
    "        \n",
    "        features.append(feat)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Extract features (using small subset for speed)\n",
    "print(\"Extracting HOG features from training data...\")\n",
    "X_train, y_train = extract_hog_features(train_dataset, num_samples=5000)\n",
    "print(\"Extracting HOG features from test data...\")\n",
    "X_test, y_test = extract_hog_features(test_dataset, num_samples=2000)\n",
    "\n",
    "print(f\"\\nEach image is now represented by {X_train.shape[1]} numbers\")\n",
    "print(\"These numbers describe the edges and shapes in the image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Classifier on HOG Features\n",
    "\n",
    "Now we'll train a **Logistic Regression** model on these features.\n",
    "\n",
    "**What is Logistic Regression?**\n",
    "- A simple machine learning algorithm\n",
    "- Draws lines to separate different classes\n",
    "- Works well for simple problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training classifier on HOG features...\")\n",
    "clf = LogisticRegression(max_iter=100, verbose=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate performance\n",
    "train_acc = clf.score(X_train, y_train)\n",
    "test_acc = clf.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"FEATURE ENGINEERING RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Train Accuracy: {train_acc:.1%}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.1%}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"\\n💡 Not great! Manual features can only do so much.\")\n",
    "print(\"   This is why deep learning became popular!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Data Augmentation (The Secret Weapon)\n",
    "\n",
    "**The Problem:** Real-world images vary a lot:\n",
    "- Different lighting (bright, dark, sunny, cloudy)\n",
    "- Different angles (front view, side view, tilted)\n",
    "- Different positions (centered, off to the side)\n",
    "- Different colors (faded, vibrant)\n",
    "\n",
    "If we only train on the original images, the model might not recognize objects in different conditions!\n",
    "\n",
    "**The Solution: Data Augmentation**\n",
    "\n",
    "Create variations of training images by randomly:\n",
    "- **Flipping** them horizontally\n",
    "- **Cropping** different parts\n",
    "- **Rotating** slightly\n",
    "- **Changing colors** (brightness, contrast)\n",
    "\n",
    "**Why This Matters:**\n",
    "- Forces the model to learn features that work under ANY conditions\n",
    "- Dramatically improves performance on new images\n",
    "- **This is KEY for the competition!**\n",
    "\n",
    "**Real-World Analogy:**\n",
    "\n",
    "Imagine learning to recognize your friend:\n",
    "- If you only see them in one outfit, one lighting, one angle → you might not recognize them elsewhere\n",
    "- If you see them in many situations → you'll always recognize them\n",
    "\n",
    "That's what data augmentation does for AI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what augmentation looks like!\n",
    "\n",
    "# Define augmentation transforms\n",
    "augment_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=1.0),  # Always flip for demo\n",
    "    transforms.RandomRotation(15),  # Rotate up to 15 degrees\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3),  # Adjust colors\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Get one image\n",
    "original_img, label = train_dataset[100]\n",
    "\n",
    "# Show original + 5 augmented versions\n",
    "fig, axes = plt.subplots(1, 6, figsize=(15, 3))\n",
    "\n",
    "axes[0].imshow(original_img.permute(1, 2, 0))\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Generate augmented versions\n",
    "for i in range(1, 6):\n",
    "    from PIL import Image\n",
    "    pil_img = Image.fromarray((original_img.permute(1,2,0).numpy() * 255).astype(np.uint8))\n",
    "    aug_img = augment_transform(pil_img)\n",
    "    axes[i].imshow(aug_img.permute(1, 2, 0))\n",
    "    axes[i].set_title(f\"Augmented {i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Data Augmentation Example - {classes[label]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 The model sees many variations of each image during training!\")\n",
    "print(\"   This helps it learn robust features that work in different conditions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Convolutional Neural Networks (The Modern Way)\n",
    "\n",
    "**The Big Idea:** Instead of humans designing features, let the computer learn them automatically!\n",
    "\n",
    "**What is a CNN?**\n",
    "\n",
    "A CNN is a type of neural network that learns a hierarchy of features:\n",
    "\n",
    "1. **Layer 1**: Learns simple patterns (edges, lines, colors)\n",
    "2. **Layer 2**: Combines simple patterns into parts (wheels, eyes, wings)\n",
    "3. **Layer 3**: Combines parts into objects (car, cat, bird)\n",
    "\n",
    "**Key Components:**\n",
    "\n",
    "- **Convolutional Layers (Conv2d)**: Learn filters that detect patterns\n",
    "  - Like Instagram filters, but learned automatically!\n",
    "  \n",
    "- **ReLU (Activation)**: Adds non-linearity\n",
    "  - Allows the network to learn complex patterns\n",
    "  \n",
    "- **Pooling Layers (MaxPool)**: Reduce size, keep important info\n",
    "  - Like creating a summary of a book\n",
    "  \n",
    "- **Fully Connected Layers**: Make final decision\n",
    "  - Combines all learned features to classify the image\n",
    "\n",
    "**Advantages:**\n",
    "- No manual feature design needed!\n",
    "- Learns optimal features automatically\n",
    "- Much better performance (~70-80%+ on CIFAR-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple CNN with 3 convolutional blocks\n",
    "    \n",
    "    Architecture:\n",
    "    Block 1: Conv -> ReLU -> Pool (learns simple edges)\n",
    "    Block 2: Conv -> ReLU -> Pool (learns shapes)\n",
    "    Block 3: Conv -> ReLU -> Pool (learns objects)\n",
    "    Classifier: Dropout -> Linear (makes final decision)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1: Detect simple patterns (edges, colors)\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 3 input channels (RGB) -> 32 filters\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduce size: 32×32 -> 16×16\n",
    "            \n",
    "            # Block 2: Detect complex patterns (shapes, textures)\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32 -> 64 filters\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # Reduce size: 16×16 -> 8×8\n",
    "            \n",
    "            # Block 3: Detect high-level patterns (object parts)\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),  # 64 -> 128 filters\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))  # Global pooling: 8×8 -> 1×1\n",
    "        )\n",
    "        \n",
    "        # Classification layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),  # Randomly turn off 50% of neurons (prevents overfitting)\n",
    "            nn.Linear(128, 10)  # 128 features -> 10 class scores\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Pass input through the network\"\"\"\n",
    "        x = self.features(x)  # Extract features\n",
    "        x = x.view(x.size(0), -1)  # Flatten to 1D\n",
    "        x = self.classifier(x)  # Classify\n",
    "        return x\n",
    "\n",
    "# Create the model\n",
    "model = SimpleCNN().to(device)\n",
    "print(\"Model created!\")\n",
    "print(f\"Number of learnable parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(\"These are the numbers the model will learn during training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data with Augmentation\n",
    "\n",
    "Now we'll create two versions of the data:\n",
    "- **Training data**: WITH augmentation (to learn robust features)\n",
    "- **Test data**: WITHOUT augmentation (to fairly evaluate performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transforms: WITH augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Test transforms: WITHOUT augmentation\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset_aug = datasets.CIFAR10(root='./data', train=True, transform=train_transform)\n",
    "test_dataset_norm = datasets.CIFAR10(root='./data', train=False, transform=test_transform)\n",
    "\n",
    "# Create data loaders (feed data to model in batches)\n",
    "train_loader = DataLoader(train_dataset_aug, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset_norm, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Data ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model!\n",
    "\n",
    "**How Training Works:**\n",
    "\n",
    "1. **Forward Pass**: Show images to the model, get predictions\n",
    "2. **Calculate Loss**: Measure how wrong the predictions are\n",
    "3. **Backward Pass**: Calculate how to adjust each parameter to reduce loss\n",
    "4. **Update Weights**: Adjust parameters to make better predictions\n",
    "5. **Repeat**: Do this thousands of times!\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Loss Function**: Measures prediction error\n",
    "- **Optimizer**: Updates model weights (we use Adam)\n",
    "- **Epoch**: One complete pass through all training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: Measures how wrong predictions are\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: Updates model weights to reduce loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()  # Set to training mode\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        loss.backward()  # Calculate gradients\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        # Track accuracy\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return 100. * correct / total\n",
    "\n",
    "def test(model, loader, device):\n",
    "    \"\"\"Evaluate the model\"\"\"\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():  # Don't calculate gradients (saves memory)\n",
    "        for images, labels in tqdm(loader, desc=\"Testing\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return 100. * correct / total\n",
    "\n",
    "# Train for 5 epochs\n",
    "print(\"Starting training...\\n\")\n",
    "for epoch in range(1, 6):\n",
    "    print(f\"Epoch {epoch}/5\")\n",
    "    train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    test_acc = test(model, test_loader, device)\n",
    "    print(f\"Train Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"Test Accuracy:  {test_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL CNN RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Final Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n💡 Much better than feature engineering (~40%)!\")\n",
    "print(\"   CNNs learn the best features automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What We Learned\n",
    "\n",
    "### 1. Feature Engineering (Old Way)\n",
    "- ❌ Humans manually design features\n",
    "- ❌ Limited performance (~40-50%)\n",
    "- ❌ Requires expert knowledge\n",
    "\n",
    "### 2. Data Augmentation (The Secret)\n",
    "- ✅ Create variations of training images\n",
    "- ✅ Forces model to learn robust features\n",
    "- ✅ **KEY INSIGHT**: If test data varies, train with variations!\n",
    "\n",
    "### 3. CNNs (Modern Way)\n",
    "- ✅ Automatically learns features\n",
    "- ✅ Much better performance (~70-80%+)\n",
    "- ✅ No manual feature design needed\n",
    "\n",
    "---\n",
    "\n",
    "## For the Competition (CIFAR-100)\n",
    "\n",
    "**What's Different?**\n",
    "- 100 classes instead of 10 (much harder!)\n",
    "- Test set will have challenging augmentations\n",
    "\n",
    "**How to Win?**\n",
    "1. **Data augmentation is CRITICAL!** Add more augmentations to training\n",
    "2. **Improve the model** - Add more layers, try BatchNorm, experiment!\n",
    "3. **Train longer** - 20-50 epochs instead of 5\n",
    "4. **Tune hyperparameters** - Learning rate, batch size, optimizer\n",
    "\n",
    "**Remember:** Models trained with augmentation generalize better to augmented test sets!\n",
    "\n",
    "Good luck! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
