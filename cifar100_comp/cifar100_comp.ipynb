{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100 Competition - Data Exploration\n",
    "\n",
    "Welcome to the CIFAR-100 image classification competition!\n",
    "\n",
    "**Goal:** Build a CNN that achieves the highest accuracy on the test set.\n",
    "\n",
    "**Dataset:** CIFAR-100 has 100 classes of 32Ã—32 color images.\n",
    "\n",
    "**What You'll Do:**\n",
    "1. Explore the CIFAR-100 dataset in this notebook\n",
    "2. Modify `model.py` to improve the CNN architecture\n",
    "3. Modify `main.py` to add data augmentations\n",
    "4. Run `python main.py` to train and generate `submission.csv`\n",
    "5. Submit `submission.csv` to Kaggle\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                      'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore CIFAR-100\n",
    "\n",
    "CIFAR-100 is much more challenging than CIFAR-10:\n",
    "- 100 fine-grained classes (vs 10 in CIFAR-10)\n",
    "- Same tiny 32Ã—32 pixel images\n",
    "- 500 training images per class (50,000 total)\n",
    "- 100 test images per class (10,000 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-100 dataset\n",
    "basic_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=basic_transform)\n",
    "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=basic_transform)\n",
    "\n",
    "print(f'Training images: {len(train_dataset)}')\n",
    "print(f'Test images: {len(test_dataset)}')\n",
    "print(f'Number of classes: 100')\n",
    "print(f'Image shape: {train_dataset[0][0].shape}')  # (3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualize Random Samples\n",
    "\n",
    "Let's see what kinds of images we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from the training set\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_dataset[np.random.randint(len(train_dataset))]\n",
    "    ax.imshow(img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    ax.set_title(f'Class {label}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Random CIFAR-100 Training Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nCIFAR-100 has 100 different classes!')\n",
    "print('Much more challenging than CIFAR-10 (10 classes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Class Distribution\n",
    "\n",
    "Let's verify that the dataset is balanced (equal number of images per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class in training set\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "label_counts = Counter(train_labels)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.bar(label_counts.keys(), label_counts.values(), color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Class ID')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('CIFAR-100 Training Set - Class Distribution')\n",
    "plt.axhline(y=500, color='red', linestyle='--', label='Expected: 500 per class')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f'Total classes: {len(label_counts)}')\n",
    "print(f'Images per class: {label_counts[0]}')\n",
    "print('Dataset is balanced!' if len(set(label_counts.values())) == 1 else 'Dataset is imbalanced!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Image Statistics\n",
    "\n",
    "Understanding pixel value distributions helps us choose good normalization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 random images and compute statistics\n",
    "sample_images = [train_dataset[i][0] for i in np.random.choice(len(train_dataset), 1000, replace=False)]\n",
    "sample_tensor = torch.stack(sample_images)\n",
    "\n",
    "# Compute mean and std per channel\n",
    "mean = sample_tensor.mean(dim=[0, 2, 3])\n",
    "std = sample_tensor.std(dim=[0, 2, 3])\n",
    "\n",
    "print('Pixel Statistics (from 1000 random images):')\n",
    "print(f'Mean (R, G, B): {mean.numpy()}')\n",
    "print(f'Std  (R, G, B): {std.numpy()}')\n",
    "print('\\nNote: Values are in [0, 1] range after ToTensor()')\n",
    "print('These statistics can be used for normalization in your transforms!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualize Samples from Specific Classes\n",
    "\n",
    "Let's look at multiple samples from the same class to understand intra-class variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random class\n",
    "target_class = np.random.randint(0, 100)\n",
    "\n",
    "# Find all images from this class\n",
    "class_images = [(img, label) for img, label in train_dataset if label == target_class][:16]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(class_images):\n",
    "        img, label = class_images[i]\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "plt.suptitle(f'16 Samples from Class {target_class}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Notice the variation within the same class!')\n",
    "print(f'Different angles, lighting, colors - this is why data augmentation helps!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare with Test Set\n",
    "\n",
    "Let's visualize some test images to see if they look different from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = test_dataset[np.random.randint(len(test_dataset))]\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.set_title(f'Class {label}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Random CIFAR-100 Test Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Standard CIFAR-100 test set looks similar to training set.')\n",
    "print('However, the COMPETITION test set will have augmentations!')\n",
    "print('(noise, blur, color shifts, etc.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Training Your Model\n",
    "\n",
    "Now that you've explored the data, it's time to build and train your model!\n",
    "\n",
    "### 1. Improve the Model (`model.py`)\n",
    "- Add more convolutional layers\n",
    "- Add BatchNorm for better training\n",
    "- Try different architectures\n",
    "- Experiment with dropout rates\n",
    "\n",
    "### 2. Add Data Augmentation (`main.py`)\n",
    "**This is KEY to success!** The competition test set has augmentations.\n",
    "\n",
    "Suggested augmentations in `get_transforms()`:\n",
    "```python\n",
    "transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)\n",
    "transforms.RandomRotation(15)\n",
    "transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "transforms.RandomGrayscale(p=0.1)\n",
    "```\n",
    "\n",
    "### 3. Train the Model\n",
    "```bash\n",
    "python main.py\n",
    "```\n",
    "\n",
    "This will:\n",
    "- Train your model for 10 epochs (adjust EPOCHS in main.py for longer training)\n",
    "- Save the best model as `best_model.pth`\n",
    "- Generate `submission.csv` for Kaggle (if test.csv and test_images/ are present)\n",
    "\n",
    "### 4. Submit to Kaggle\n",
    "1. Download `test.csv` and `test_images.zip` from Kaggle\n",
    "2. Unzip `test_images.zip` in the `cifar100_comp/` folder\n",
    "3. Run `python main.py` to generate `submission.csv`\n",
    "4. Upload `submission.csv` to Kaggle!\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Success ðŸ’¡\n",
    "\n",
    "1. **Data Augmentation is CRITICAL!** The test set has augmentations.\n",
    "2. Train longer (20-50 epochs) for better performance\n",
    "3. Experiment with different learning rates and optimizers\n",
    "4. Add BatchNorm to your model architecture\n",
    "5. Monitor training vs test accuracy to detect overfitting\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
